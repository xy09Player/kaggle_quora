{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.nn import functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = True\n",
    "if flag:\n",
    "    train_file = 'data/train.csv'\n",
    "    embedding_file = 'data/glove.840B.300d.txt'\n",
    "    test_file = 'data/test.csv'\n",
    "else:\n",
    "    train_file = '../input/train.csv'\n",
    "    embedding_file = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    test_file = '../input/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "batch_size = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_model_rnn_1 = {\n",
    "    'mode': 'LSTM',\n",
    "    'hidden_size': 150,\n",
    "    'dropout_p': 0.2,\n",
    "    'encoder_dropout_p': 0.1,\n",
    "    'encoder_layer_num': 1,\n",
    "    'is_bn': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = config_model_rnn_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    " - 分词\n",
    " - train：长度筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deal_data(data, max_len=100, is_train=True):\n",
    "    df = pd.read_csv(data)\n",
    "    questions = df['question_text'].values\n",
    "    question_word_lists = [nltk.word_tokenize(q) for q in questions]\n",
    "    question_word_list_len = [len(q) for q in question_word_lists]\n",
    "    if is_train:\n",
    "        target = df['target'].values\n",
    "        question_os = []\n",
    "        target_os = []\n",
    "        for q, t, l in zip(question_word_lists, target, question_word_list_len):\n",
    "            if l <= max_len:\n",
    "                question_os.append(q)\n",
    "                target_os.append(t)\n",
    "        print('deal_data, retain data:%d/%d' % (len(question_os), len(questions)))\n",
    "        return question_os, target_os\n",
    "\n",
    "    else:\n",
    "        question_os = question_word_lists\n",
    "        return question_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_data, retain data:1306111/1306122\n"
     ]
    }
   ],
   "source": [
    "train_questions, train_targets = deal_data(train_file, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_questions = deal_data(test_file, max_len=max_len, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake\n",
    "# train_questions, train_targets = train_questions[: 100000], train_targets[: 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立词表\n",
    " - glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(questions, glove_file):\n",
    "\n",
    "    # 初始化embedding字典\n",
    "    def get_matrixs(word, *nums):\n",
    "        return word, np.asarray(nums, dtype='float32')\n",
    "    embedding_dict = dict([get_matrixs(*o.split(' ')) for o in open(glove_file, 'r')])\n",
    "\n",
    "    # 初始化词表\n",
    "    word_set = set()\n",
    "    for q in questions:\n",
    "        for word in q:\n",
    "            word_set.add(word)\n",
    "    vocab_all_size = len(word_set)\n",
    "\n",
    "    # 词表删选\n",
    "    word_set = set()\n",
    "    for q in questions:\n",
    "        for word in q:\n",
    "            if word in embedding_dict:\n",
    "                word_set.add(word)\n",
    "    vocab_size = len(word_set)\n",
    "\n",
    "    print('words in pre-embedding, num:%d/%d, radio:%.4f' % (vocab_size, vocab_all_size, vocab_size/vocab_all_size))\n",
    "\n",
    "    # 构建词表、embedding矩阵\n",
    "    w2i = {'<pad>': 0}\n",
    "    count = 1\n",
    "    embedding = np.zeros([len(word_set)+2, 300])\n",
    "    for word in word_set:\n",
    "        if word not in w2i:\n",
    "            w2i[word] = count\n",
    "            embedding[count] = embedding_dict[word]\n",
    "            count += 1\n",
    "    w2i['<unk>'] = count\n",
    "    assert len(w2i) == len(embedding)\n",
    "\n",
    "    print('build_word_embedding,  vocab size:%d' % len(w2i))\n",
    "\n",
    "    return w2i, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-be0d050619b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_word_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_questions\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b558d827dd89>\u001b[0m in \u001b[0;36mbuild_word_embedding\u001b[0;34m(questions, glove_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 初始化词表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b558d827dd89>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 初始化词表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b558d827dd89>\u001b[0m in \u001b[0;36mget_matrixs\u001b[0;34m(word, *nums)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 初始化embedding字典\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_matrixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w2i, embedding = build_word_embedding(train_questions+test_questions, embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2indexs(words, lang):\n",
    "\n",
    "    def word2index(word_list):\n",
    "        return [lang[word] if word in lang else lang['<unk>'] for word in word_list]\n",
    "\n",
    "    return [word2index(word_list) for word_list in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = word2indexs(train_questions, w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(words, max_len, pad_index=0):\n",
    "\n",
    "    def padd(word_list):\n",
    "        if len(word_list) > max_len:\n",
    "            tmp = word_list[: max_len]\n",
    "        else:\n",
    "            tmp = word_list + [pad_index] * (max_len - len(word_list))\n",
    "        return tmp\n",
    "\n",
    "    results = [padd(word_list) for word_list in words]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = padding(train_questions, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机划分训练集、验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions, val_questions, train_targets, val_targets = model_selection.train_test_split(\n",
    "        train_questions, train_targets, test_size=0.1, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_questions) == len(train_targets)\n",
    "assert len(val_questions) == len(val_targets)\n",
    "print('train size:%d, val size:%d' % (len(train_questions), len(val_questions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建train、val dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, shuffle, drop_last):\n",
    "    dataset = [torch.LongTensor(d) for d in dataset]\n",
    "    dataset = data.TensorDataset(*dataset)\n",
    "    data_iter = data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "    return data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(\n",
    "    dataset=[train_questions, train_targets],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    dataset=[val_questions, val_targets],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding\n",
    " - 基础embedding\n",
    " - <unk> 可训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\" standard embedding \"\"\"\n",
    "    def __init__(self, embedding):\n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        self.vocab_size = embedding.shape[0]\n",
    "        self.w2v_size = embedding.shape[1]\n",
    "\n",
    "        self.embedding_fix = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim=self.w2v_size,\n",
    "            padding_idx=0,\n",
    "            _weight=torch.Tensor(embedding)\n",
    "        )\n",
    "        self.embedding_fix.weight.requires_grad = False\n",
    "\n",
    "        self.embedding_v = nn.Embedding(\n",
    "            num_embeddings=2,\n",
    "            embedding_dim=self.w2v_size,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.embedding_dim = self.embedding_fix.embedding_dim\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: (batch_size, c_len)\n",
    "        :return: (batch_size, c_len, w2v)\n",
    "        \"\"\"\n",
    "        embedding_1 = self.embedding_fix(tensor)\n",
    "\n",
    "        tensor = tensor - (self.vocab_size - self.embedding_v.num_embeddings)\n",
    "        tensor = f.relu(tensor)\n",
    "        embedding_2 = self.embedding_v(tensor)\n",
    "\n",
    "        embedding = embedding_1 + embedding_2\n",
    "\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder\n",
    " - LSTM、 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "\n",
    "    def __init__(self, param):\n",
    "        super(Rnn, self).__init__()\n",
    "\n",
    "        self.mode = param['mode']\n",
    "        self.input_size = param['input_size']\n",
    "        self.hidden_size = param['hidden_size']\n",
    "        self.dropout_p = param['encoder_dropout_p']\n",
    "        self.directional = True\n",
    "        self.layer_num = param['encoder_layer_num']\n",
    "        self.is_bn = param['is_bn']\n",
    "\n",
    "        if self.mode == 'LSTM':\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.layer_num,\n",
    "                bidirectional=self.directional,\n",
    "                dropout=self.dropout_p if self.layer_num > 1 else 0\n",
    "            )\n",
    "        elif self.mode == 'GRU':\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.layer_num,\n",
    "                bidirectional=self.directional,\n",
    "                dropout=self.dropout_p if self.layer_num > 1 else 0\n",
    "            )\n",
    "\n",
    "        if self.is_bn:\n",
    "            self.layer_norm = nn.LayerNorm(self.input_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\" use xavier_uniform to initialize rnn weights \"\"\"\n",
    "        ih = (param for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param for name, param in self.named_parameters() if 'bias' in name)\n",
    "\n",
    "        for t in ih:\n",
    "            torch.nn.init.xavier_uniform_(t)\n",
    "        for t in hh:\n",
    "            torch.nn.init.orthogonal_(t)\n",
    "        for t in b:\n",
    "            torch.nn.init.constant_(t, 0)\n",
    "\n",
    "    def forward(self, vec, mask):\n",
    "        \"\"\"\n",
    "        :param vec: (seq_len, batch_size, input_size)\n",
    "        :param mask: (batch_size, seq_len)\n",
    "        :return: (seq_len, batch_size, hidden_size*directional_num)\n",
    "        \"\"\"\n",
    "\n",
    "        # layer normalization\n",
    "        if self.is_bn:\n",
    "            seq_len, batch_size, input_size = vec.size\n",
    "            vec = vec.contiguous().view(-1, input_size)\n",
    "            vec = self.layer_norm(vec)\n",
    "            vec = vec.view(seq_len, batch_size, input_size)\n",
    "\n",
    "        # dropout\n",
    "        vec = self.dropout(vec)\n",
    "\n",
    "        # forward\n",
    "        lengths = mask.long().sum(1)\n",
    "        length_sort, idx_sort = torch.sort(lengths, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "\n",
    "        v_sort = vec.index_select(1, idx_sort)\n",
    "        v_pack = nn.utils.rnn.pack_padded_sequence(v_sort, length_sort)\n",
    "        outputs, _ = self.rnn(v_pack, None)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs.index_select(1, idx_unsort)\n",
    "\n",
    "        # 未填充， outputs的第一维可能小于seq_len\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model：Bi-Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model_Rnn(nn.Module):\n",
    "    \"\"\" rnn \"\"\"\n",
    "    def __init__(self, param):\n",
    "        super(Model_Rnn, self).__init__()\n",
    "\n",
    "        self.hidden_size = param['hidden_size']\n",
    "        self.dropout_p = param['dropout_p']\n",
    "\n",
    "        # embedding\n",
    "        self.embedding = Embedding(param['embedding'])\n",
    "\n",
    "        # encoder\n",
    "        param['input_size'] = self.embedding.embedding_dim\n",
    "        self.encoder = Rnn(param)\n",
    "\n",
    "        # outputs\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(param['dropout_p'])\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        questions = batch[0]\n",
    "\n",
    "        # mask\n",
    "        def get_mask(tensor): return torch.ne(tensor, 0)\n",
    "        question_mask = get_mask(questions)\n",
    "\n",
    "        # embedding\n",
    "        question_vec = self.embedding(questions)\n",
    "        question_vec = question_vec.transpose(0, 1)\n",
    "\n",
    "        # encoder (seq_len, batch_size, h*2)\n",
    "        question_vec = self.encoder(question_vec, question_mask)\n",
    "\n",
    "        # output\n",
    "        question_vec = torch.sum(question_vec, dim=0)\n",
    "        question_mask = question_mask.long().sum(1)\n",
    "        question_mask = question_mask.view(-1, 1).float()\n",
    "        question_vec = question_vec / question_mask  # (batch_size, h*2)\n",
    "\n",
    "        question_vec = self.dropout(question_vec)\n",
    "        output = self.fc1(question_vec)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc2(output)  # (batch_size, 1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model_Rnn(param)\n",
    "model = model.cuda()\n",
    "model_best_state = None\n",
    "loss_best = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_param = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(optimizer_param, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_num = 0\n",
    "for parameter in model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        model_param_num += parameter.nelement()\n",
    "print('start training, param_num:%d' % model_param_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "train_c = 0\n",
    "t_nums = len(train_questions) // batch_size\n",
    "every_nums = t_nums // 10\n",
    "time0 = time.time()\n",
    "for e in range(epochs):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = [b.cuda() for b in batch]\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss_value = criterion(outputs, batch[1].view(-1, 1).float())\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_value.item()\n",
    "        train_c += 1\n",
    "\n",
    "        if train_c % every_nums == 0:\n",
    "            val_loss = 0\n",
    "            val_c = 0\n",
    "            correct_num = 0\n",
    "            sum_num = 0\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for val_batch in val_loader:\n",
    "                    val_batch = [b.cuda() for b in val_batch]\n",
    "                    outputs = model(val_batch)\n",
    "                    loss_value = criterion(outputs, val_batch[1].view(-1, 1).float())\n",
    "\n",
    "                    correct_num += ((outputs > 0.5).long() == val_batch[1].view(-1, 1)).sum().item()\n",
    "                    sum_num += outputs.size(0)\n",
    "\n",
    "                    val_loss += loss_value.item()\n",
    "                    val_c += 1\n",
    "            print('training, epochs:%2d, steps:%2d/%2d, train_loss:%.4f, val_loss:%.4f, accuracy:%.4f, time:%4ds' %\n",
    "                      (e, (i+1), t_nums, train_loss/train_c, val_loss/val_c, correct_num/sum_num, time.time()-time0))\n",
    "\n",
    "            if loss_best > (val_loss/val_c):\n",
    "                loss_best = val_loss / val_c\n",
    "                model_best_state = copy.deepcopy(model.state_dict())\n",
    "print('training, best_loss:%.4f' % loss_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阈值选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_Rnn(param)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(model_best_state)\n",
    "model.eval()\n",
    "scores = np.arange(0, 1, 0.05)\n",
    "best_score = -1\n",
    "best_accuracy = 0\n",
    "for score in scores:\n",
    "    correct_num = 0\n",
    "    sum_num = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_batch = [b.cuda() for b in val_batch]\n",
    "            outputs = model(val_batch)\n",
    "            correct_num += ((outputs > score).long() == val_batch[1].view(-1, 1)).sum().item()\n",
    "            sum_num += outputs.size(0)\n",
    "    print('score choosing, score:%.2f, accuracy:%.4f' % (score, correct_num/sum_num))\n",
    "    if best_accuracy < correct_num / sum_num:\n",
    "        best_score = score\n",
    "        best_accuracy = correct_num / sum_num\n",
    "print('valing, best_score:%.2f, best_accuracy:%.4f' % (best_score, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = deal_data(test_file, is_train=False)\n",
    "print('test size:%d' % len(test_questions))\n",
    "w2i_test, embedding_test = build_word_embedding(test_questions, embedding_file)\n",
    "test_questions = word2indexs(test_questions, w2i_test)\n",
    "test_questions = padding(test_questions, max_len)\n",
    "test_loader = get_dataloader(\n",
    "    dataset=[test_questions],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 测试模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model_Rnn(param)\n",
    "model.load_state_dict(model_best_state)\n",
    "model.embedding.embedding_fix = nn.Embedding(\n",
    "    num_embeddings=embedding_test.shape[0],\n",
    "    embedding_dim=embedding_test.shape[1],\n",
    "    padding_idx=0,\n",
    "    _weight=torch.Tensor(embedding_test)\n",
    ")\n",
    "model.embedding.vocab_size = embedding_test.shape[0]\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        test_batch = [b.cuda() for b in test_batch]\n",
    "        outputs = model(test_batch)\n",
    "        outputs = (outputs > best_score).long()\n",
    "        result += outputs.view(-1).cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_file)\n",
    "submission = pd.DataFrame(\n",
    "    {'qid': test_df['qid'], 'prediction': result},\n",
    "    columns=['qid', 'prediction']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
