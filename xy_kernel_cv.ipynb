{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single1.1\n",
    "    - 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85303894087dc5932280b60714598edf7c5f472e"
   },
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d507375804994a3ad7df90141a1f00fe52708410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.nn import functional as f\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "9134af4e005ab367a65341f1ecf644063e0ff442",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2d9e617dca859d88dde8f89e5a2195c07b85d481",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe92f701a5362663caef2fd7013b8b3cb469a626"
   },
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e06157e5bed5be93f0c4222cfc8fe06b3ebbeb50",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    train_file = 'data/train.csv'\n",
    "    embedding_file = 'data/glove.840B.300d.txt'\n",
    "#     embedding_file = 'data/paragram_300_sl999.txt'\n",
    "    test_file = 'data/test.csv'\n",
    "else:\n",
    "    train_file = '../input/train.csv'\n",
    "    embedding_file = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "#     embedding_file = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    test_file = '../input/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "75677a1551b6f292afacc9eeb77e8125c7da91c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 72  # 有待进一步确定\n",
    "max_features = 120000  # 有待进一步确定\n",
    "batch_size = 512\n",
    "test_batch_size = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e379e12441b9997624f9339e6d27546014c679f"
   },
   "source": [
    "## 数据预处理\n",
    " - 分词\n",
    " - train：长度筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e68fca601d915cc23cfffb851d5153ab97b882b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len:1306122\n",
      "test_len:56370\n",
      "time:29\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# lower\n",
    "df_train['question_text'] = df_train['question_text'].str.lower()\n",
    "df_test['question_text'] = df_test['question_text'].str.lower()\n",
    "\n",
    "# add split \n",
    "df_train['question_text'] = df_train['question_text'].apply(lambda x: clean_text(x))\n",
    "df_test['question_text'] = df_test['question_text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# fill up missing values\n",
    "train_questions = df_train['question_text'].fillna(\"_##_\").values\n",
    "test_questions = df_test['question_text'].fillna(\"_##_\").values\n",
    "\n",
    "# split word\n",
    "train_questions = [q.split() for q in train_questions]\n",
    "test_questions = [q.split() for q in test_questions]\n",
    "\n",
    "train_targets = df_train['target'].values\n",
    "\n",
    "print('train_len:%d' % (len(train_questions)))\n",
    "print('test_len:%d' % (len(test_questions)))\n",
    "print('time:%d' % (time.time() - time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53bd9f482e3dae99edae3bbaa658851f480a843f"
   },
   "source": [
    "## 建立词表\n",
    " - glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63b6a76328d257fb54b297b57262c44c1a1627ab"
   },
   "source": [
    "### 构建embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6719ad8573afe4dbde04f2c8c1c85e57747764fb"
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(questions, glove_file):\n",
    "\n",
    "    # 初始化embedding字典\n",
    "    def get_matrixs(word, *nums):\n",
    "        return word, np.asarray(nums, dtype='float32')\n",
    "    if glove_file in ['data/paragram_300_sl999.txt', '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt']:\n",
    "        embedding_dict = dict(get_matrixs(*o.split(\" \")) for o in open(glove_file, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "    else:\n",
    "        embedding_dict = dict([get_matrixs(*o.split(' ')) for o in open(glove_file)])\n",
    "    \n",
    "    # 初始化词表\n",
    "    vocab = {}\n",
    "    for q in questions:\n",
    "        for word in q:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "\n",
    "    # 检查词表覆盖率、词表删选\n",
    "    known_num = 0\n",
    "    all_num = 0\n",
    "    word_set = []\n",
    "    for word in vocab.keys():\n",
    "        if word in embedding_dict:\n",
    "            known_num += vocab[word]\n",
    "            word_set.append(word)\n",
    "        all_num += vocab[word]\n",
    "        \n",
    "    print('words in pre-embedding, num:%d/%d, radio:%.4f' % (len(word_set), len(vocab), len(word_set)/len(vocab)))\n",
    "    print('known words in all text:%.4f' % (known_num/all_num))\n",
    "\n",
    "\n",
    "    # 构建词表、embedding矩阵\n",
    "    w2i = {'<pad>': 0}\n",
    "    count = 1\n",
    "    embedding = np.zeros([len(word_set)+2, 300])\n",
    "    for word in word_set:\n",
    "        if word not in w2i:\n",
    "            w2i[word] = count\n",
    "            embedding[count] = embedding_dict[word]\n",
    "            count += 1\n",
    "    w2i['<unk>'] = count\n",
    "    assert len(w2i) == len(embedding)\n",
    "\n",
    "    print('build_word_embedding,  vocab size:%d' % len(w2i))\n",
    "\n",
    "    return w2i, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4c6819f4305d0b7956d9e92484c76dd4fb482dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in pre-embedding, num:126280/200487, radio:0.6299\n",
      "known words in all text:0.9939\n",
      "build_word_embedding,  vocab size:126282\n",
      "time:89\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "w2i, embedding = build_word_embedding(train_questions+test_questions, embedding_file)\n",
    "print('time:%d' % (time.time() - time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bfdee4cec7ed3c09da106b61a8a5746ff66a3c8"
   },
   "source": [
    "## index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "2be2fc775022283ab06238bb2a1739777103c9aa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2indexs(words, lang):\n",
    "\n",
    "    def word2index(word_list):\n",
    "        return [lang[word] if word in lang else lang['<unk>'] for word in word_list]\n",
    "\n",
    "    return [word2index(word_list) for word_list in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8b881c73802cce5c5c2275a6c9423e24e677e618",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = word2indexs(train_questions, w2i)\n",
    "test_questions = word2indexs(test_questions, w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "944f227129409453124641b6ab8beea97d7ddd11"
   },
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "b20c4e6cde03d984511bc96bef4fbfce543abd80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(words, max_len, pad_index=0):\n",
    "\n",
    "    def padd(word_list):\n",
    "        if len(word_list) > max_len:\n",
    "            tmp = word_list[: max_len]\n",
    "        else:\n",
    "            tmp = word_list + [pad_index] * (max_len - len(word_list))\n",
    "        return tmp\n",
    "\n",
    "    results = [padd(word_list) for word_list in words]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ca2e86a65494d6e6c32ad0186203fa5342684a86",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = padding(train_questions, max_len)\n",
    "test_questions = padding(test_questions, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = np.array(train_questions)\n",
    "train_targets = np.array(train_targets)\n",
    "test_questions = np.array(test_questions)\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=333).split(train_questions, train_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "054e558157369b07840010595616b16dafc22532"
   },
   "source": [
    "## 构建train、val dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6654991e8d8a4b5a0dd1f738bf7735576be2aae4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, shuffle, drop_last):\n",
    "    dataset = [torch.LongTensor(d) for d in dataset]\n",
    "    dataset = data.TensorDataset(*dataset)\n",
    "    data_iter = data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "    return data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61ecbdefcaa039cd9fe46829d72eef62e6e3fda2"
   },
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4c6861720b17852ec446d9c3b65902c0c7bbbcd"
   },
   "source": [
    "### embedding\n",
    " - 基础embedding\n",
    " - <unk> 可训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0272decdc34d1ed9b53684810429fb2696e8f56f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\" standard embedding \"\"\"\n",
    "    def __init__(self, embedding):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.vocab_size = embedding.shape[0]\n",
    "        self.w2v_size = embedding.shape[1]\n",
    "        self.embedding_fix = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim=self.w2v_size,\n",
    "            padding_idx=0,\n",
    "            _weight=torch.Tensor(embedding)\n",
    "        )\n",
    "        self.embedding_fix.weight.requires_grad = False\n",
    "        self.embedding_v = nn.Embedding(\n",
    "            num_embeddings=2,\n",
    "            embedding_dim=self.w2v_size,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.embedding_dim = self.embedding_fix.embedding_dim\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: (batch_size, c_len)\n",
    "        :return: (batch_size, c_len, w2v)\n",
    "        \"\"\"\n",
    "        embedding_1 = self.embedding_fix(tensor)\n",
    "        tensor = tensor - (self.vocab_size - self.embedding_v.num_embeddings)\n",
    "        tensor = f.relu(tensor)\n",
    "        embedding_2 = self.embedding_v(tensor)\n",
    "        embedding = embedding_1 + embedding_2\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6560b4ccf5d02bd65d5edf976b1bc08d38717f52"
   },
   "source": [
    "### encoder\n",
    " - LSTM、 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "5821668017fe766cf3f92d46f40d5693b2d59b67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, param):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.mode = param['mode']\n",
    "        self.input_size = param['input_size']\n",
    "        self.hidden_size = param['hidden_size']\n",
    "        self.dropout_p = param['dropout_p']\n",
    "        self.directional = True\n",
    "        self.layer_num = param['encoder_layer_num']\n",
    "        self.is_bn = param['is_bn']\n",
    "        if self.mode == 'LSTM':\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.layer_num,\n",
    "                bidirectional=self.directional,\n",
    "                dropout=self.dropout_p if self.layer_num > 1 else 0\n",
    "            )\n",
    "        elif self.mode == 'GRU':\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.layer_num,\n",
    "                bidirectional=self.directional,\n",
    "                dropout=self.dropout_p if self.layer_num > 1 else 0\n",
    "            )\n",
    "        if self.is_bn:\n",
    "            self.layer_norm = nn.LayerNorm(self.input_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\" use xavier_uniform to initialize rnn weights \"\"\"\n",
    "        ih = (param for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for t in ih:\n",
    "            torch.nn.init.xavier_uniform_(t)\n",
    "        for t in hh:\n",
    "            torch.nn.init.orthogonal_(t)\n",
    "        for t in b:\n",
    "            torch.nn.init.constant_(t, 0)\n",
    "            \n",
    "    def forward(self, vec, mask):\n",
    "        \"\"\"\n",
    "        :param vec: (seq_len, batch_size, input_size)\n",
    "        :param mask: (batch_size, seq_len)\n",
    "        :return: (seq_len, batch_size, hidden_size*directional_num)\n",
    "        \"\"\"\n",
    "        # layer normalization\n",
    "        if self.is_bn:\n",
    "            seq_len, batch_size, input_size = vec.size\n",
    "            vec = vec.contiguous().view(-1, input_size)\n",
    "            vec = self.layer_norm(vec)\n",
    "            vec = vec.view(seq_len, batch_size, input_size)\n",
    "\n",
    "        # forward\n",
    "        lengths = mask.long().sum(1)\n",
    "        length_sort, idx_sort = torch.sort(lengths, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort)\n",
    "\n",
    "        v_sort = vec.index_select(1, idx_sort)\n",
    "        v_pack = nn.utils.rnn.pack_padded_sequence(v_sort, length_sort)\n",
    "        outputs, _ = self.rnn(v_pack, None)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs.index_select(1, idx_unsort)\n",
    "        \n",
    "        # 未填充， outputs的第一维可能小于seq_len\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27a1f14706845eece4025a998272ee3e03b7aa31"
   },
   "source": [
    "### self-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "32d6118f18cd2056767b393d12711b237e752611",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelfAttn(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SelfAttn, self).__init__()\n",
    "\n",
    "        self.wq = nn.Linear(input_size, input_size//2)\n",
    "        self.v = nn.Linear(input_size//2, 1)\n",
    "\n",
    "    def forward(self, question_vec, question_mask):\n",
    "        \"\"\"\n",
    "        :param question_vec: (seq_len, batch_size, input_size)\n",
    "        :param question_mask: (batch_size, seq_len)\n",
    "        :return: (batch_size, input_size)\n",
    "        \"\"\"\n",
    "        wq = self.wq(question_vec)\n",
    "        wq = torch.tanh(wq)\n",
    "        s = self.v(wq).squeeze(2).transpose(0, 1)  # (batch_size, seq_len)\n",
    "\n",
    "        mask = question_mask.eq(0)\n",
    "        s.masked_fill_(mask, -float('inf'))\n",
    "        s = f.softmax(s, dim=1)\n",
    "\n",
    "        result = torch.bmm(s.unsqueeze(1), question_vec.transpose(0, 1)).squeeze(1)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19a69dc409757e76cba81b45889b5cc973dfb702"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model_xy(nn.Module):\n",
    "    \"\"\" rnn \"\"\"\n",
    "    def __init__(self, param):\n",
    "        super(Model_xy, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding = Embedding(param['embedding'])\n",
    "        \n",
    "        # lstm\n",
    "        param['input_size'] = self.embedding.embedding_dim\n",
    "        param['mode'] = 'LSTM'\n",
    "        self.lstm = Rnn(param)\n",
    "        \n",
    "        # gru\n",
    "        param['mode'] = 'GRU'\n",
    "        self.gru = Rnn(param)\n",
    "        \n",
    "        # attn\n",
    "        self.lstm_attn = SelfAttn(param['hidden_size']*2)\n",
    "        self.gru_attn = SelfAttn(param['hidden_size']*2)\n",
    "        \n",
    "        # outputs\n",
    "        self.fc1 = nn.Linear(param['hidden_size']*12, param['hidden_size'])\n",
    "        self.fc2 = nn.Linear(param['hidden_size'], 1)\n",
    "        \n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(param['dropout_p'])\n",
    "        self.dropout_emb = nn.Dropout(param['dropout_emb_p'])\n",
    "        \n",
    "        # init\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.constant_(self.fc1.bias, 0.0)\n",
    "        torch.nn.init.constant_(self.fc2.bias, 0.0) \n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        questions = batch[0]\n",
    "        \n",
    "        # mask\n",
    "        def get_mask(tensor): return torch.ne(tensor, 0)\n",
    "        question_mask = get_mask(questions)\n",
    "        mask_len = question_mask.long().sum(1).view(-1, 1).float()\n",
    "        \n",
    "        # embedding\n",
    "        question_vec = self.embedding(questions)\n",
    "        question_vec = question_vec.transpose(0, 1)\n",
    "        question_vec = self.dropout_emb(question_vec)\n",
    "        \n",
    "        # lstm\n",
    "        lstm_vec = self.lstm(question_vec, question_mask)\n",
    "        \n",
    "        # lstm:avg\n",
    "        lstm_avg = torch.sum(lstm_vec, dim=0)\n",
    "        lstm_avg = lstm_avg / mask_len  # (batch_size, h*2)\n",
    "        \n",
    "        # lstm:max\n",
    "        lstm_max = torch.max(lstm_vec, dim=0)[0]\n",
    "        \n",
    "        # lstm:attn\n",
    "        lstm_attn = self.lstm_attn(lstm_vec, question_mask[:, :lstm_vec.size(0)])\n",
    "        \n",
    "        # gru\n",
    "        gru_vec = self.gru(question_vec, question_mask)\n",
    "        \n",
    "        # gru:avg\n",
    "        gru_avg = torch.sum(gru_vec, dim=0)\n",
    "        gru_avg = gru_avg / mask_len\n",
    "        \n",
    "        # gru: max\n",
    "        gru_max = torch.max(gru_vec, dim=0)[0]\n",
    "        \n",
    "        # gru:attn\n",
    "        gru_attn = self.gru_attn(gru_vec, question_mask[:, :gru_vec.size(0)])\n",
    "        \n",
    "        vec = torch.cat([lstm_avg, gru_avg, lstm_max, gru_max, lstm_attn, gru_attn], dim=1)\n",
    "        \n",
    "        # output: \n",
    "        output = f.relu(self.fc1(vec))\n",
    "        output = self.dropout(output)\n",
    "        output = torch.sigmoid(self.fc2(output))  # (batch_size, 1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09b46aa988f54e0b68339096926fba9474369065"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "9002d4664a61f543027ea8ece151c3e8bfce7183",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(param):\n",
    "    if param['name'] == 'model_xy':\n",
    "        model = Model_xy(param)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # train/val loader\n",
    "    i = param['data_i']\n",
    "    train_x = train_questions[splits[i][0]]\n",
    "    train_y = train_targets[splits[i][0]]\n",
    "    train_loader = get_dataloader(\n",
    "        dataset=[train_x, train_y],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_x = train_questions[splits[i][1]]\n",
    "    val_y = train_targets[splits[i][1]]\n",
    "    val_loader = get_dataloader(\n",
    "        dataset=[val_x, val_y],\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer_param = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adam(optimizer_param, lr=param['lr'], weight_decay=param['l2_decay'])\n",
    "    lr = param['lr']\n",
    "    \n",
    "    model_param_num = 0\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            model_param_num += parameter.nelement()\n",
    "    print('%s, param_num:%d' % (param['name'], model_param_num))\n",
    "    \n",
    "    # train\n",
    "    model_best_state = None\n",
    "    train_loss = 0\n",
    "    train_c = 0\n",
    "    t_nums = len(train_loader)\n",
    "    every_nums = t_nums // param['every_print']\n",
    "    time0 = time.time()\n",
    "    loss_val_last = 99999.0\n",
    "    loss_best = 999\n",
    "    accuracy_best = 0\n",
    "    e_best = 0\n",
    "    \n",
    "    for e in range(param['epoch']):\n",
    "        train_loss = 0\n",
    "        train_c = 0\n",
    "        \n",
    "#         if e == 0:\n",
    "#             lr = param['lr']\n",
    "#         elif e == 1:\n",
    "#             lr = param['lr'] \n",
    "#         elif e == 2:\n",
    "#             lr = param['lr'] \n",
    "            \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "                    \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch = [b.cuda() for b in batch]\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss_value = criterion(outputs, batch[1].view(-1, 1).float())\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss_value.item()\n",
    "            train_c += 1\n",
    "            \n",
    "\n",
    "#             if train_c % every_nums == 0 and (param['need_print'] or (param['need_print'] is False and e==param['epoch']-1)):\n",
    "#             if ((i % every_nums == 0 and i != 0) or (i+1 == t_nums)) and e+1 == param['epoch']:    \n",
    "            if (i % every_nums == 0 and i != 0) or (i+1 == t_nums):\n",
    "                val_loss = 0\n",
    "                val_c = 0\n",
    "                correct_num = 0\n",
    "                sum_num = 0\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for val_batch in val_loader:\n",
    "                        val_batch = [b.cuda() for b in val_batch]\n",
    "                        outputs = model(val_batch)\n",
    "                        loss_value = criterion(outputs, val_batch[1].view(-1, 1).float())\n",
    "\n",
    "                        correct_num += ((outputs > 0.5).long() == val_batch[1].view(-1, 1)).sum().item()\n",
    "                        sum_num += outputs.size(0)\n",
    "\n",
    "                        val_loss += loss_value.item()\n",
    "                        val_c += 1\n",
    "                print('training, epochs:%2d, steps:%2d/%2d, train_loss:%.4f, val_loss:%.4f, accuracy:%.4f, lr:%.4f, time:%4ds' %\n",
    "                        (e, (i+1), t_nums, train_loss/train_c, val_loss/val_c, correct_num/sum_num, lr, time.time()-time0))\n",
    "\n",
    "                train_loss = 0\n",
    "                train_c = 0\n",
    "                \n",
    "#                 if loss_val_last < val_loss / val_c:\n",
    "#                     lr = lr * 0.5\n",
    "#                     if lr < 0.001:\n",
    "#                         lr = 0.001\n",
    "\n",
    "                if loss_best > (val_loss / val_c):\n",
    "                    accuracy_best = correct_num/sum_num\n",
    "                    loss_best = val_loss / val_c\n",
    "                    e_best = e\n",
    "                    model_best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                loss_val_last = val_loss / val_c\n",
    "                \n",
    "\n",
    "    print('training, best_eposh:%d, best_loss:%.4f, best_accuracy:%.4f' % (e_best, loss_best, accuracy_best))\n",
    "\n",
    "    model.load_state_dict(model_best_state)\n",
    "    model.eval()  \n",
    "    \n",
    "    # eval\n",
    "    if True:\n",
    "        scores = np.arange(0.1, 0.501, 0.01)\n",
    "        accuracy = []\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                val_batch = [b.cuda() for b in val_batch]\n",
    "                outputs = model(val_batch)\n",
    "                outputs = outputs.view(-1).cpu().numpy().tolist()\n",
    "                y_pred += outputs\n",
    "                y_true += val_batch[1].view(-1).cpu().numpy().tolist()\n",
    "        \n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        for score in scores:\n",
    "            y_pred_tmp = (y_pred > score).astype(int).tolist()\n",
    "            acc_tmp = metrics.f1_score(y_true, y_pred_tmp)\n",
    "            accuracy.append(acc_tmp)\n",
    "            if False:\n",
    "                print('score choosing, score:%.2f, accuracy:%.4f' % (score, acc_tmp))\n",
    "        accuracy = np.array(accuracy)\n",
    "        best_index = np.argmax(accuracy)\n",
    "        best_score = scores[best_index]\n",
    "        best_f1 = accuracy[best_index]\n",
    "        print('valing, best_score:%.2f, best_accuracy:%.4f' % (best_score, best_f1))\n",
    "    \n",
    "    return model, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8518864d88721397ff9da163af7b45262ab6bb7"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 model training...\n",
      "model_xy, param_num:724003\n",
      "training, epochs: 0, steps:409/2041, train_loss:0.1311, val_loss:0.1146, accuracy:0.9533, lr:0.0010, time:  39s\n",
      "training, epochs: 0, steps:817/2041, train_loss:0.1157, val_loss:0.1074, accuracy:0.9573, lr:0.0010, time:  77s\n",
      "training, epochs: 0, steps:1225/2041, train_loss:0.1102, val_loss:0.1134, accuracy:0.9556, lr:0.0010, time: 115s\n",
      "training, epochs: 0, steps:1633/2041, train_loss:0.1064, val_loss:0.1030, accuracy:0.9589, lr:0.0010, time: 154s\n",
      "training, epochs: 0, steps:2041/2041, train_loss:0.1064, val_loss:0.1011, accuracy:0.9594, lr:0.0010, time: 192s\n",
      "training, epochs: 1, steps:409/2041, train_loss:0.1007, val_loss:0.1006, accuracy:0.9599, lr:0.0010, time: 230s\n",
      "training, epochs: 1, steps:817/2041, train_loss:0.1000, val_loss:0.0995, accuracy:0.9600, lr:0.0010, time: 268s\n",
      "training, epochs: 1, steps:1225/2041, train_loss:0.1010, val_loss:0.0992, accuracy:0.9604, lr:0.0010, time: 306s\n",
      "training, epochs: 1, steps:1633/2041, train_loss:0.0999, val_loss:0.0991, accuracy:0.9597, lr:0.0010, time: 345s\n",
      "training, epochs: 1, steps:2041/2041, train_loss:0.0998, val_loss:0.0994, accuracy:0.9604, lr:0.0010, time: 383s\n",
      "training, epochs: 2, steps:409/2041, train_loss:0.0926, val_loss:0.0982, accuracy:0.9604, lr:0.0010, time: 421s\n",
      "training, epochs: 2, steps:817/2041, train_loss:0.0933, val_loss:0.0969, accuracy:0.9614, lr:0.0010, time: 459s\n",
      "training, epochs: 2, steps:1225/2041, train_loss:0.0939, val_loss:0.0967, accuracy:0.9612, lr:0.0010, time: 497s\n",
      "training, epochs: 2, steps:1633/2041, train_loss:0.0952, val_loss:0.0961, accuracy:0.9613, lr:0.0010, time: 536s\n",
      "training, epochs: 2, steps:2041/2041, train_loss:0.0953, val_loss:0.0983, accuracy:0.9600, lr:0.0010, time: 574s\n",
      "training, epochs: 3, steps:409/2041, train_loss:0.0869, val_loss:0.0966, accuracy:0.9613, lr:0.0010, time: 613s\n"
     ]
    }
   ],
   "source": [
    "model_group = []\n",
    "model_f1 = []\n",
    "\n",
    "for i in range(len(splits)):\n",
    "    time0 = time.time()\n",
    "    config_model_i = {\n",
    "        'data_i':i,\n",
    "        'epoch':5,\n",
    "        'name':'model_xy',\n",
    "        'hidden_size':100,\n",
    "        'dropout_emb_p':0.1,\n",
    "        'dropout_p':0.2,\n",
    "        'embedding':embedding,\n",
    "        'encoder_layer_num':1,\n",
    "        'is_bn':False,\n",
    "        'l2_decay':0,\n",
    "        'need_print':True,\n",
    "        'lr':1e-3,\n",
    "        'every_print':5       \n",
    "    }\n",
    "    print('start %d model training...' % (i+1))\n",
    "    model_i, f1_i = train(config_model_i)\n",
    "    model_group.append(model_i)\n",
    "    model_f1.append(f1_i)\n",
    "    print('%d model training finish, time:%d\\n' % (i+1, time.time()-time0))   \n",
    "print(model_f1)\n",
    "print('result_f1:%.4f' % (sum(model_f1)/len(model_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 均值\n",
    "def ensemble_mean(model_result):\n",
    "    y_pred = np.zeros(shape=[len(model_result[0])])\n",
    "    for r in model_result:\n",
    "        y_pred += np.array(r)\n",
    "    y_pred = y_pred / len(model_result)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(\n",
    "    dataset=[test_questions],\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "model_result = [[] for _ in range(len(model_group))]\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        test_batch = [b.cuda() for b in test_batch]\n",
    "\n",
    "        for index in range(len(model_group)):\n",
    "            outputs = model_group[index](test_batch)\n",
    "            outputs = outputs.view(-1).cpu().numpy().tolist()\n",
    "            model_result[index] += outputs\n",
    "\n",
    "    # 集成策略：均值\n",
    "    print('jiaquan mean,', end='')\n",
    "    y_pred = ensemble_mean(model_result)\n",
    "    y_pred = (y_pred > 0.34 ).astype(int).tolist()\n",
    "    result = y_pred\n",
    "\n",
    "print('test, ensemble, time:%d' % (time.time()-time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_file)\n",
    "submission = pd.DataFrame(\n",
    "    {'qid': test_df['qid'], 'prediction': result},\n",
    "    columns=['qid', 'prediction']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time:%d' % (time.time()-time_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
